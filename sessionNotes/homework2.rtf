{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red34\green45\blue53;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c17647\c23137\c27059;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww28600\viewh14980\viewkind0
\deftab720
\pard\pardeftab720\sl360\sa240\partightenfactor0

\f0\fs32 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The aim of this exercise is to train you in debugging networks using the good old print function and also tensorboard. To simulate poor training, we will train a multilayer perceptron using the CIFAR data.\
1. Use the CIFAR data set reader from the first homework and read the CIFAR-10 files again.\'a0\cb1 \uc0\u8232 \cb3 2. Apply random noise to the image\'a0\
Add random values t image. Add two image together. (2*55\
\pard\pardeftab720\sl360\sa240\partightenfactor0
\cf2 \cb1 Range 0-20 10%\
\uc0\u8232 \cb3 3. Convert the image to float and scale to [0.0, 1.0] by dividing the pixel values by the highest pixel value.\
0 -255 => 0 - 1   \cb1 \uc0\u8232 \cb3 4. Convert all labels to onehot encoding\
numpy, tensor flow \cb1 \uc0\u8232 \cb3 5. Build a 3-layer multilayer perceptron of size [512, 256, 128].\'a0\
Hidden layer of sizes.  Final out is 10\
3012 , 512, 256, 128, 10\cb1 \uc0\u8232 \cb3 6. Create a tensorboard summary for plotting the histogram of the weights of the three layers.\
use  tensor flow histogram\cb1 \uc0\u8232 \cb3 7. Also write the cost / loss at the end of each epoch to tensorboard.\
\cb1 \uc0\u8232 \cb3 8. Train the network with learning rates of [0.1, 0.01, 0.001]. You will notice that the network will not converge well.\cb1 \uc0\u8232 \cb3 9. Submit the snapshot of the histograms for the three learning rates. Describe your observations.\
4 weight will be submitted. For histogram for each learning rate.   Use sigmoid function.\
sigmoid Butter layers change fast, input layers not change fast. \
\
}