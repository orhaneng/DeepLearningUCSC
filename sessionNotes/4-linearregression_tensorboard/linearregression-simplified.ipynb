{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.425879397 455.0 68.0 387.0\n",
      "count    398.000000\n",
      "mean       1.934259\n",
      "std        1.042698\n",
      "min        0.680000\n",
      "25%        1.042500\n",
      "50%        1.485000\n",
      "75%        2.620000\n",
      "max        4.550000\n",
      "Name: displacement, dtype: float64\n",
      "count    398.000000\n",
      "mean       0.235146\n",
      "std        0.078160\n",
      "min        0.090000\n",
      "25%        0.175000\n",
      "50%        0.230000\n",
      "75%        0.290000\n",
      "max        0.466000\n",
      "Name: mpg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# https://archive.ics.uci.edu/ml/datasets/auto+mpg\n",
    "autompg = pd.read_csv('auto_mpg.csv')\n",
    "autompg_disp = autompg['displacement'].astype(float)\n",
    "autompg_mpg = autompg['mpg'].astype(float)\n",
    "mean_disp = np.mean(autompg_disp)\n",
    "min_disp = np.min(autompg_disp)\n",
    "max_disp = np.max(autompg_disp)\n",
    "print(mean_disp, max_disp, min_disp, max_disp-min_disp)\n",
    "autompg_disp = autompg_disp.apply(lambda x:x/100)\n",
    "print(autompg_disp.describe())\n",
    "autompg_mpg = autompg_mpg.apply(lambda x: x/100)\n",
    "print(autompg_mpg.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get a batch of data\n",
    "def getbatch(xval, yval, arraylength, batchsize=30):\n",
    "    count = 0 \n",
    "    while count < arraylength/batchsize:\n",
    "        randstart = random.randint(0, arraylength-batchsize-1)\n",
    "        count += 1\n",
    "        yield (xval[randstart:randstart+batchsize], yval[randstart:randstart+batchsize])\n",
    "\n",
    "# Test\n",
    "#for i in getbatch(train_X, train_Y, n_samples):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.003\n",
    "n_epochs = 3000\n",
    "display_step = 100\n",
    "train_X = np.asarray(autompg_disp)\n",
    "train_Y = np.asarray(autompg_mpg)\n",
    "n_samples = train_X.shape[0]\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "## Defining X and Y as placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(np.random.randn())\n",
    "b = tf.Variable(np.random.randn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# predicted is X*W+b. \n",
    "pred = tf.add(tf.multiply(X, W), b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cost, optimizer and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# The cost function is ((predicted-actual)^2)/2*n_samples. \n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Add all ops that need to be initialized\n",
    "# The initilization needs to be run only after session is created\n",
    "# as in session.run(init) below.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the session \n",
    "This will run the graph and use all the tensors that were previously defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0100 and cost = 0.182815567\n",
      "Epoch = 0200 and cost = 0.062778436\n",
      "Epoch = 0300 and cost = 0.053206019\n",
      "Epoch = 0400 and cost = 0.047320731\n",
      "Epoch = 0500 and cost = 0.042143021\n",
      "Epoch = 0600 and cost = 0.037409283\n",
      "Epoch = 0700 and cost = 0.033323165\n",
      "Epoch = 0800 and cost = 0.029665982\n",
      "Epoch = 0900 and cost = 0.026475605\n",
      "Epoch = 1000 and cost = 0.023622980\n",
      "Epoch = 1100 and cost = 0.021083884\n",
      "Epoch = 1200 and cost = 0.018840501\n",
      "Epoch = 1300 and cost = 0.016828144\n",
      "Epoch = 1400 and cost = 0.015064315\n",
      "Epoch = 1500 and cost = 0.013499096\n",
      "Epoch = 1600 and cost = 0.012093076\n",
      "Epoch = 1700 and cost = 0.010835682\n",
      "Epoch = 1800 and cost = 0.009711892\n",
      "Epoch = 1900 and cost = 0.008731600\n",
      "Epoch = 2000 and cost = 0.007870960\n",
      "Epoch = 2100 and cost = 0.007106712\n",
      "Epoch = 2200 and cost = 0.006422998\n",
      "Epoch = 2300 and cost = 0.005820717\n",
      "Epoch = 2400 and cost = 0.005285838\n",
      "Epoch = 2500 and cost = 0.004814483\n",
      "Epoch = 2600 and cost = 0.004394567\n",
      "Epoch = 2700 and cost = 0.004020926\n",
      "Epoch = 2800 and cost = 0.003692986\n",
      "Epoch = 2900 and cost = 0.003405114\n",
      "Epoch = 3000 and cost = 0.003140800\n",
      "The final W = -0.0043 and b = 0.2165\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for (x, y) in getbatch(train_X, train_Y, n_samples):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch = {:04d} and cost = {:.9f}\".format(epoch+1, c))\n",
    "\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    finalW = sess.run(W)\n",
    "    finalb = sess.run(b)\n",
    "    print(\"The final W = %0.4f and b = %0.4f\" %(finalW, finalb))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nteract": {
   "version": "0.8.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
