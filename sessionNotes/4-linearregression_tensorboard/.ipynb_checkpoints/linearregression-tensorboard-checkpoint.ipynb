{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"optimizer_graph.png\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "Data from https://archive.ics.uci.edu/ml/datasets/auto+mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autompg = pd.read_csv('auto_mpg.csv')\n",
    "# Extract only the displacement and mpg column\n",
    "autompg_disp = autompg['displacement'].astype(float)\n",
    "autompg_mpg = autompg['mpg'].astype(float)\n",
    "\n",
    "# Scale data\n",
    "autompg_disp = autompg_disp.apply(lambda x:x/100)\n",
    "print(autompg_disp.describe())\n",
    "autompg_mpg = autompg_mpg.apply(lambda x: x/100)\n",
    "print(autompg_mpg.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy data series to numpy array\n",
    "train_X = np.asarray(autompg_disp)\n",
    "train_Y = np.asarray(autompg_mpg)\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get batch of data\n",
    "def getbatch(xval, yval, arraylength, batchsize=30):\n",
    "    count = 0 \n",
    "    while count < arraylength/batchsize:\n",
    "        randstart = random.randint(0, arraylength-batchsize-1)\n",
    "        count += 1\n",
    "        yield (xval[randstart:randstart+batchsize], yval[randstart:randstart+batchsize])\n",
    "\n",
    "# Test\n",
    "#for i in getbatch(train_X, train_Y, n_samples):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "n_epochs = 3000\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining X and Y as placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders and variables\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(np.random.randn())\n",
    "b = tf.Variable(np.random.randn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model\n",
    "\n",
    "predicted is X*W+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.add(tf.multiply(X, W), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cost and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cost function is ((predicted-actual)^2)/2*n_samples. \n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Add all ops that need to be initialized\n",
    "# The initilization needs to be run only after session is created\n",
    "# as in session.run(init) below.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary writer and its configuration\n",
    "writer = tf.summary.FileWriter(\"./logs\", graph=tf.get_default_graph())\n",
    "tf.summary.scalar(\"Cost\", cost)\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the session \n",
    "This will run the graph and use all the tensors that were previously defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for (x, y) in getbatch(train_X, train_Y, n_samples):\n",
    "            _, costval, merged_summary = sess.run([optimizer, cost, merged_summary_op], \n",
    "                                                  feed_dict={X: x, Y: y})\n",
    "        writer.add_summary(merged_summary, epoch)\n",
    "        # Every few display step, calculate and print cost\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch = {:04d} and cost = {:.9f}\".format(epoch+1, c))\n",
    "\n",
    "    # At the end of the training, print the cost and W and b\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    finalW = sess.run(W)\n",
    "    finalb = sess.run(b)\n",
    "    print(\"The final W = %0.4f and b = %0.4f\" %(finalW, finalb))\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening tensorboard\n",
    "\n",
    "In the command line, type \"tensorboard --logdir=./logs\"\n",
    "This will launch a local webserver at port 6006. Visit http://localhost:6006 in a browser. Then click on the label 'Cost' to see the graph.  You can make the graph larger by clicking on the rectangular button at the bottom left corner of the graph. You can zoom in to the graph by drawing a box around the region to zoom in. You can zoom out by double clicking the graph.\n",
    "\n",
    "NOTE 1: Please make sure that you ran this code to completion and that the log folder exist. \n",
    "\n",
    "NOTE 2: Make sure that you are in the directory that has the logs folder when you execute the tensorboard command. \n",
    "\n",
    "On Windows, visiting http://localhost:6006 returns an error. Instead use the link provided by Tensorboard in the terminal. On the other hand, some people using Mac have experienced problem using the link provided by Tensorboard.  In such cases, use localhost:6006 instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nteract": {
   "version": "0.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
